{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f738631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client as MCPClient\n",
    "\n",
    "from typing import Optional\n",
    "from pprint import pp\n",
    "\n",
    "# Add src directory to path for imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../src'))\n",
    "from helper import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a05e1",
   "metadata": {},
   "source": [
    "## Get Tools from MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb6ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MCP_URL = PROJECT_ROOT / \"src/app_mcp.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf7cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def list_tools_from_mcp(server_path: str):\n",
    "    async with MCPClient(server_path) as mcp_client:\n",
    "        tools = await mcp_client.list_tools()\n",
    "    print(\"Available Tools:\\n\\n - \" + '\\n - '.join([tool.name for tool in tools]))\n",
    "\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1113a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Tools:\n",
      "\n",
      " - analyze_script_punct\n",
      " - llm_chat\n"
     ]
    }
   ],
   "source": [
    "async def generate_available_tools(mcp_url: str):\n",
    "    \"\"\"Generates JSON for available tools from MCP that can be passed directly to PG models\"\"\"\n",
    "    tools = await list_tools_from_mcp(mcp_url)\n",
    "    available_tools = []\n",
    "\n",
    "    for tool in tools:\n",
    "        tool_dict = {}\n",
    "        tool_dict[\"type\"] = \"function\"\n",
    "        tool_dict[\"name\"] = tool.name\n",
    "        tool_dict[\"description\"] = tool.description\n",
    "        tool_dict[\"parameters\"] = tool.inputSchema\n",
    "        available_tools.append({\"type\": \"function\", \"function\": tool_dict, \"strict\": True})\n",
    "\n",
    "    return available_tools\n",
    "\n",
    "# Example usage:\n",
    "AVAILABLE_TOOLS = await generate_available_tools(MCP_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2cbf6",
   "metadata": {},
   "source": [
    "## Connect to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf41646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predictionguard import PredictionGuard\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "PREDICTIONGUARD_URL = os.getenv(\"PREDICTIONGUARD_URL\", \"https://api.predictionguard.com\")\n",
    "API_KEY = os.getenv(\"PREDICTIONGUARD_API_KEY\")\n",
    "MODEL = os.getenv(\"PREDICTIONGUARD_DEFAULT_MODEL\", \"gpt-oss-120b\")\n",
    "MAX_COMPLETION_TOKENS = 10000\n",
    "TEMPERATURE = None\n",
    "\n",
    "client = PredictionGuard(\n",
    "    api_key=API_KEY,\n",
    "    url=PREDICTIONGUARD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32786188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_chat(user_query: Optional[str] = None, file_name: Optional[str] = None):\n",
    "    system_prompt = f\"\"\"You are an expert bible translator and consultant.\\\n",
    "You are responsible for analyzing translation tasks and provide accurate analysis and recommendations.\\\n",
    "You can either use the tools provided to you or use `llm_call` if you want to answer directly.\\\n",
    "Do not make up your own analysis, only use the tools provided.\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "    \n",
    "    res = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=AVAILABLE_TOOLS,\n",
    "            tool_choice=\"auto\", \n",
    "            max_completion_tokens=MAX_COMPLETION_TOKENS,\n",
    "            temperature=TEMPERATURE\n",
    "        )\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed6aa6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-01eebe4597d34342b5e6946183ed5693',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1759829092,\n",
       " 'model': 'OpenAI/gpt-oss-120b',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': '',\n",
       "    'tool_calls': [{'id': 'chatcmpl-tool-aa633d2e69c146d896737937183652a6',\n",
       "      'type': 'function',\n",
       "      'index': 0,\n",
       "      'function': {'name': 'analyze_script_punct',\n",
       "       'arguments': '{\"input_filename\": null, \"input_string\": \"\\\\u0628\\\\u0646\\\\u0643\\\\u062a\\\\u0628 \\\\u0644\\\\u0643\\\\u0645 \\\\u0639\\\\u0646 \\\\u0627\\\\u0644\\\\u0644\\\\u064a \\\\u0643\\\\u0627\\\\u0646 \\\\u0645\\\\u0646 \\\\u0627\\\\u0644\\\\u0628\\\\u062f\\\\u0627\\\\u064a\\\\u0629 \\\\u0628\\\\u062e\\\\u0635\\\\u0648\\\\u0635 \\\\u0643\\\\u0644\\\\u0645\\\\u0629 \\\\u0627\\\\u0644\\\\u062d\\\\u064a\\\\u0627\\\\u0629 \\\\u0639\\\\u0646 \\\\u0627\\\\u0644\\\\u0644\\\\u064a\", \"lang_code\": \"ar\", \"lang_name\": \"Arabic\"}'}}]},\n",
       "   'finish_reason': 'tool_calls'}],\n",
       " 'usage': {'prompt_tokens': 0,\n",
       "  'completion_tokens': 0,\n",
       "  'total_tokens': 0,\n",
       "  'completion_tokens_details': {'reasoning_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0}}}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = initiate_chat(user_query=\"Analyze the punctuation for this text: 'بنكتب لكم عن اللي كان من البداية بخصوص كلمة الحياة عن اللي'.\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2682cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def call_tool(mcp_url: str, tool_name: str, tool_args):\n",
    "    \"\"\"\n",
    "    Calls the specified tool on the MCP server with the given arguments.\n",
    "\n",
    "    Args:\n",
    "        mcp_url (str): The MCP server URL.\n",
    "        tool_name (str): The name of the tool to call.\n",
    "        **tool_args: Arguments to pass to the tool.\n",
    "\n",
    "    Returns:\n",
    "        dict: The result of the tool call.\n",
    "    \"\"\"\n",
    "    tool = next((t['function']['name'] for t in AVAILABLE_TOOLS if t['function']['name'] == tool_name), None)\n",
    "    if not tool:\n",
    "        raise ValueError(f\"Tool '{tool_name}' not found on MCP server.\")\n",
    "   \n",
    "    async with MCPClient(MCP_URL) as mcp_client:\n",
    "        result = await mcp_client.call_tool(tool, tool_args)\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greek-room-api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
